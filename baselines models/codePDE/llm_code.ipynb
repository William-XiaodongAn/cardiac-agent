{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c115afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import math\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "# Define the Laplacian kernel at the module level for efficiency.\n",
    "# It's a 5-point stencil for a 2D grid.\n",
    "_LAPLACIAN_KERNEL = torch.tensor([[0., 1., 0.], [1., -4., 1.], [0., 1., 0.]]).view(1, 1, 3, 3)\n",
    "\n",
    "def _compute_laplacian_2d(grid: torch.Tensor, dx: float) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Computes the 2D Laplacian of a grid using a 5-point stencil convolution.\n",
    "    Handles No-Flux (Neumann) boundary conditions via 'replicate' padding.\n",
    "\n",
    "    Args:\n",
    "        grid (torch.Tensor): The input grid of shape [batch_size, N, N].\n",
    "        dx (float): The spatial step size.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: The computed Laplacian of the grid.\n",
    "    \"\"\"\n",
    "    # The kernel must be on the same device as the input grid.\n",
    "    kernel = _LAPLACIAN_KERNEL.to(grid.device)\n",
    "    \n",
    "    # Add a channel dimension for conv2d compatibility: [B, N, N] -> [B, 1, N, N].\n",
    "    grid_ch = grid.unsqueeze(1)\n",
    "    \n",
    "    # Pad the grid by one layer on all sides. 'replicate' mode copies the edge\n",
    "    # values, which is a standard way to implement Neumann boundary conditions\n",
    "    # for a finite difference scheme.\n",
    "    padded_grid = F.pad(grid_ch, (1, 1, 1, 1), mode='replicate')\n",
    "    \n",
    "    # Apply the convolution. 'valid' padding means no extra padding is added by the conv layer itself.\n",
    "    laplacian = F.conv2d(padded_grid, kernel, padding='valid')\n",
    "    \n",
    "    # Scale the result by 1/dx^2 and remove the channel dimension to get the final result.\n",
    "    return laplacian.squeeze(1) / (dx**2)\n",
    "\n",
    "def _compute_reactions(u: torch.Tensor, v: torch.Tensor, w: torch.Tensor, params: Dict) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Computes the reaction terms (RHS of the ODEs) for the PDE system.\n",
    "    This function is fully vectorized using PyTorch operations.\n",
    "\n",
    "    Args:\n",
    "        u, v, w (torch.Tensor): Current state variables.\n",
    "        params (Dict): Dictionary of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[torch.Tensor, torch.Tensor, torch.Tensor]: The reaction terms for u, v, and w.\n",
    "    \"\"\"\n",
    "    # Heaviside step functions are implemented as boolean masks converted to float (0.0 or 1.0).\n",
    "    H_uc = (u >= params['V_c']).float()\n",
    "    H_uv = (u >= params['V_v']).float()\n",
    "\n",
    "    # Calculate ionic currents as per the model equations.\n",
    "    I_fi = -v * H_uc * (u - params['V_c']) * (1 - u) / params['tau_d']\n",
    "    I_so = u * (1 - H_uc) / params['tau_0'] + H_uc / params['tau_r']\n",
    "    I_si = -w * (1 + torch.tanh(params['k'] * (u - params['V_csi']))) / (2 * params['tau_si'])\n",
    "\n",
    "    # Total reaction term for u (dudt_reaction). Note: the PDE has a minus sign before this term.\n",
    "    dudt_reaction = (I_fi + I_so + I_si) / params['C_m']\n",
    "\n",
    "    # Gating variable v's time constant (tau_mv) is dependent on u.\n",
    "    tau_mv = (1.0 - H_uv) * params['tau_v1'] + H_uv * params['tau_v2']\n",
    "\n",
    "    # dv/dt is computed using torch.where for conditional logic based on u.\n",
    "    dvdt = torch.where(\n",
    "        u < params['V_c'],\n",
    "        (1.0 - v) / tau_mv,\n",
    "        -v / params['tau_pv']\n",
    "    )\n",
    "\n",
    "    # dw/dt is also computed using torch.where for its conditional logic.\n",
    "    dwdt = torch.where(\n",
    "        u < params['V_c'],\n",
    "        (1.0 - w) / params['tau_mw'],\n",
    "        -w / params['tau_pw']\n",
    "    )\n",
    "\n",
    "    return dudt_reaction, dvdt, dwdt\n",
    "\n",
    "def solver(u_init: np.ndarray, \n",
    "           v_init: np.ndarray, \n",
    "           w_init: np.ndarray, \n",
    "           fk_taud: float, \n",
    "           t_eval: List[float]) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Solves the 2D reaction-diffusion system for a batch of initial conditions\n",
    "    using the Forward Euler method on a GPU-accelerated backend.\n",
    "\n",
    "    Args:\n",
    "        u_init (np.ndarray): Initial conditions for u, shape [batch_size, N, N].\n",
    "        v_init (np.ndarray): Initial conditions for v, shape [batch_size, N, N].\n",
    "        w_init (np.ndarray): Initial conditions for w, shape [batch_size, N, N].\n",
    "        fk_taud (float): Model parameter tau_d.\n",
    "        t_eval (List[float]): A list of time points at which to evaluate and return the solution.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[torch.Tensor, torch.Tensor, torch.Tensor]: A tuple containing the solutions\n",
    "        for u, v, and w at the specified time points (including t=0). Each tensor has a\n",
    "        shape of [batch_size, len(t_eval) + 1, N, N].\n",
    "    \"\"\"\n",
    "    # 1. Setup device and parameters\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    params = {\n",
    "        'diffCoef': 0.001, 'C_m': 1.0, 'tau_pv': 7.99, 'tau_v1': 9.8,\n",
    "        'tau_v2': 312.5, 'tau_pw': 870.0, 'tau_mw': 41.0, 'tau_d': fk_taud,\n",
    "        'tau_0': 12.5, 'tau_r': 33.83, 'tau_si': 29.0, 'k': 10.0,\n",
    "        'V_csi': 0.861, 'V_c': 0.13, 'V_v': 0.04\n",
    "    }\n",
    "\n",
    "    # 2. Discretization setup\n",
    "    if u_init.shape[1] != u_init.shape[2]:\n",
    "        raise ValueError(\"Spatial domain must be square (N x N).\")\n",
    "    N = u_init.shape[1]\n",
    "    domain_size = 20.0  # Domain is [-10, 10], so total width/height is 20.0\n",
    "    dx = domain_size / (N - 1)\n",
    "\n",
    "    # Choose a small, fixed time step `dt` for the Forward Euler method.\n",
    "    # A conservative value is chosen to maintain stability, which is often\n",
    "    # dictated by the fastest reaction dynamics in such systems.\n",
    "    dt = 0.1\n",
    "    print(f\"Spatial step dx = {dx:.4f}, Time step dt = {dt:.4f}\")\n",
    "\n",
    "    # 3. Initialization\n",
    "    # Convert numpy inputs to torch tensors, set data type, and move to the selected device.\n",
    "    u = torch.from_numpy(u_init).float().to(device)\n",
    "    v = torch.from_numpy(v_init).float().to(device)\n",
    "    w = torch.from_numpy(w_init).float().to(device)\n",
    "\n",
    "    # Ensure t_eval is sorted to process time points chronologically.\n",
    "    t_eval_sorted = sorted(t_eval)\n",
    "    \n",
    "    # Store results in lists. Start with the initial state (t=0).\n",
    "    # We clone and move to CPU to prevent GPU memory accumulation and modification of stored states.\n",
    "    u_all = [u.cpu().clone()]\n",
    "    v_all = [v.cpu().clone()]\n",
    "    w_all = [w.cpu().clone()]\n",
    "\n",
    "    # 4. Main time-stepping loop\n",
    "    current_t = 0.0\n",
    "    \n",
    "    for i, target_t in enumerate(t_eval_sorted):\n",
    "        # Ensure we don't simulate backwards if target_t is less than current_t\n",
    "        if target_t > current_t:\n",
    "            # Calculate the number of steps required to reach the next evaluation time.\n",
    "            num_steps = math.ceil((target_t - current_t) / dt)\n",
    "            \n",
    "            for _ in range(num_steps):\n",
    "                # Calculate the diffusion term (Laplacian) for u.\n",
    "                lap_u = _compute_laplacian_2d(u, dx)\n",
    "                dudt_diffusion = params['diffCoef'] * lap_u\n",
    "                \n",
    "                # Calculate the reaction terms for all three variables.\n",
    "                dudt_reaction, dvdt, dwdt = _compute_reactions(u, v, w, params)\n",
    "                \n",
    "                # Perform the Forward Euler update step for each variable.\n",
    "                # Note the minus sign for dudt_reaction, as specified in the PDE.\n",
    "                u = u + dt * (dudt_diffusion - dudt_reaction)\n",
    "                v = v + dt * dvdt\n",
    "                w = w + dt * dwdt\n",
    "            \n",
    "            # Update the simulation time to reflect the steps taken.\n",
    "            current_t += num_steps * dt\n",
    "        \n",
    "        print(f\"Reached evaluation time point {target_t} at simulation time {current_t:.2f} (step {i+1}/{len(t_eval_sorted)})\")\n",
    "\n",
    "        # Store the computed state at the current time point.\n",
    "        u_all.append(u.cpu().clone())\n",
    "        v_all.append(v.cpu().clone())\n",
    "        w_all.append(w.cpu().clone())\n",
    "\n",
    "    # 5. Output formatting\n",
    "    # Stack the list of tensors along a new time dimension (dim=1).\n",
    "    # The output shape will be [batch_size, len(t_eval) + 1, N, N].\n",
    "    # Note: The requested output shape [..., N] in the prompt is assumed to be a typo\n",
    "    # for a 2D problem, so [..., N, N] is produced.\n",
    "    u_out = torch.stack(u_all, dim=1)\n",
    "    v_out = torch.stack(v_all, dim=1)\n",
    "    w_out = torch.stack(w_all, dim=1)\n",
    "    \n",
    "    print(\"Solver finished.\")\n",
    "\n",
    "    return u_out, v_out, w_out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "codePDE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
