{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb2e6b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import general_prompt,pde_descriptions,solver_template\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from google import genai\n",
    "from google.genai.types import GenerateContentConfig\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "\n",
    "fk_description = pde_descriptions.fk_description\n",
    "system_prompt = general_prompt.system_prompt\n",
    "code_generation_without_seed_prompt = general_prompt.code_generation_without_seed_prompt\n",
    "\n",
    "user_prompt = code_generation_without_seed_prompt.format(\n",
    "    pde_description=fk_description,\n",
    "    solver_template=solver_template\n",
    ")\n",
    "debugging_execution_error_prompt = general_prompt.debugging_execution_error_prompt\n",
    "debugging_nan_inf_prompt = general_prompt.debugging_nan_inf_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6df631aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### 1. Implementation Plan\n",
      "\n",
      "My approach to implementing the PDE solver is based on the **Method of Lines**, using a simple and robust numerical scheme suitable for GPU acceleration with PyTorch.\n",
      "\n",
      "1.  **Framework Selection:** I will use **PyTorch** for this task. Its tensor computation capabilities are ideal for handling the batch processing requirement, and its convolution functions provide a highly efficient way to compute the spatial derivatives on a GPU.\n",
      "\n",
      "2.  **Numerical Scheme:**\n",
      "    *   **Time Integration:** I will use the **Forward Euler method**. This is an explicit, first-order method that is straightforward to implement. To ensure numerical stability, a small internal time step `dt` will be chosen, likely constrained more by the fast reaction dynamics than the diffusion term.\n",
      "    *   **Spatial Discretization:** The Laplacian operator ($\\nabla^2 u$) will be discretized using a **second-order 5-point finite difference stencil**. This operation can be efficiently implemented as a 2D convolution over the spatial grid, which is a significant performance advantage on GPUs.\n",
      "    *   **Boundary Conditions:** The No-Flux (Neumann) boundary conditions will be handled by padding the spatial grid before the convolution. PyTorch's `replicate` padding mode is a perfect and efficient way to implement this, as it effectively sets the normal derivative to zero at the boundaries.\n",
      "\n",
      "3.  **Code Structure:** The code will be modularized for clarity and reusability:\n",
      "    *   An auxiliary function, `_compute_laplacian_2d`, will be created to handle the diffusion term calculation, including padding and convolution.\n",
      "    *   Another auxiliary function, `_compute_reactions`, will calculate the non-spatial reaction terms for all three state variables ($u, v, w$). This function will encapsulate all the complex ionic current logic.\n",
      "    *   The main `solver` function will orchestrate the simulation. It will handle initialization, manage the time-stepping loop, call the helper functions, and format the output.\n",
      "\n",
      "4.  **Execution Flow:**\n",
      "    *   The solver will first initialize the device (preferring CUDA if available), model parameters, and discretization constants (`dx`, `dt`).\n",
      "    *   Input NumPy arrays will be converted to PyTorch tensors and moved to the selected device.\n",
      "    *   The main loop will iterate through the user-provided evaluation times (`t_eval`). For each target time, it will perform multiple smaller time steps using the Forward Euler method until the target time is reached.\n",
      "    *   At each `t_eval` point, the current state of the system will be saved.\n",
      "    *   Finally, the collected states (including the initial state) will be stacked into tensors of shape `[batch_size, len(t_eval) + 1, N, N]` and returned.\n",
      "    *   Informative print statements will track the solver's progress.\n",
      "\n",
      "This plan prioritizes simplicity and efficiency, adhering to the user's request for a straightforward algorithm while leveraging modern hardware capabilities.\n",
      "\n",
      "### 2. Python Implementation\n",
      "\n",
      "```python\n",
      "import torch\n",
      "import torch.nn.functional as F\n",
      "import numpy as np\n",
      "import math\n",
      "from typing import List, Tuple, Dict\n",
      "\n",
      "# Define the Laplacian kernel at the module level for efficiency.\n",
      "# It's a 5-point stencil for a 2D grid.\n",
      "_LAPLACIAN_KERNEL = torch.tensor([[0., 1., 0.], [1., -4., 1.], [0., 1., 0.]]).view(1, 1, 3, 3)\n",
      "\n",
      "def _compute_laplacian_2d(grid: torch.Tensor, dx: float) -> torch.Tensor:\n",
      "    \"\"\"\n",
      "    Computes the 2D Laplacian of a grid using a 5-point stencil convolution.\n",
      "    Handles No-Flux (Neumann) boundary conditions via 'replicate' padding.\n",
      "\n",
      "    Args:\n",
      "        grid (torch.Tensor): The input grid of shape [batch_size, N, N].\n",
      "        dx (float): The spatial step size.\n",
      "\n",
      "    Returns:\n",
      "        torch.Tensor: The computed Laplacian of the grid.\n",
      "    \"\"\"\n",
      "    # The kernel must be on the same device as the input grid.\n",
      "    kernel = _LAPLACIAN_KERNEL.to(grid.device)\n",
      "    \n",
      "    # Add a channel dimension for conv2d compatibility: [B, N, N] -> [B, 1, N, N].\n",
      "    grid_ch = grid.unsqueeze(1)\n",
      "    \n",
      "    # Pad the grid by one layer on all sides. 'replicate' mode copies the edge\n",
      "    # values, which is a standard way to implement Neumann boundary conditions\n",
      "    # for a finite difference scheme.\n",
      "    padded_grid = F.pad(grid_ch, (1, 1, 1, 1), mode='replicate')\n",
      "    \n",
      "    # Apply the convolution. 'valid' padding means no extra padding is added by the conv layer itself.\n",
      "    laplacian = F.conv2d(padded_grid, kernel, padding='valid')\n",
      "    \n",
      "    # Scale the result by 1/dx^2 and remove the channel dimension to get the final result.\n",
      "    return laplacian.squeeze(1) / (dx**2)\n",
      "\n",
      "def _compute_reactions(u: torch.Tensor, v: torch.Tensor, w: torch.Tensor, params: Dict) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
      "    \"\"\"\n",
      "    Computes the reaction terms (RHS of the ODEs) for the PDE system.\n",
      "    This function is fully vectorized using PyTorch operations.\n",
      "\n",
      "    Args:\n",
      "        u, v, w (torch.Tensor): Current state variables.\n",
      "        params (Dict): Dictionary of model parameters.\n",
      "\n",
      "    Returns:\n",
      "        Tuple[torch.Tensor, torch.Tensor, torch.Tensor]: The reaction terms for u, v, and w.\n",
      "    \"\"\"\n",
      "    # Heaviside step functions are implemented as boolean masks converted to float (0.0 or 1.0).\n",
      "    H_uc = (u >= params['V_c']).float()\n",
      "    H_uv = (u >= params['V_v']).float()\n",
      "\n",
      "    # Calculate ionic currents as per the model equations.\n",
      "    I_fi = -v * H_uc * (u - params['V_c']) * (1 - u) / params['tau_d']\n",
      "    I_so = u * (1 - H_uc) / params['tau_0'] + H_uc / params['tau_r']\n",
      "    I_si = -w * (1 + torch.tanh(params['k'] * (u - params['V_csi']))) / (2 * params['tau_si'])\n",
      "\n",
      "    # Total reaction term for u (dudt_reaction). Note: the PDE has a minus sign before this term.\n",
      "    dudt_reaction = (I_fi + I_so + I_si) / params['C_m']\n",
      "\n",
      "    # Gating variable v's time constant (tau_mv) is dependent on u.\n",
      "    tau_mv = (1.0 - H_uv) * params['tau_v1'] + H_uv * params['tau_v2']\n",
      "\n",
      "    # dv/dt is computed using torch.where for conditional logic based on u.\n",
      "    dvdt = torch.where(\n",
      "        u < params['V_c'],\n",
      "        (1.0 - v) / tau_mv,\n",
      "        -v / params['tau_pv']\n",
      "    )\n",
      "\n",
      "    # dw/dt is also computed using torch.where for its conditional logic.\n",
      "    dwdt = torch.where(\n",
      "        u < params['V_c'],\n",
      "        (1.0 - w) / params['tau_mw'],\n",
      "        -w / params['tau_pw']\n",
      "    )\n",
      "\n",
      "    return dudt_reaction, dvdt, dwdt\n",
      "\n",
      "def solver(u_init: np.ndarray, \n",
      "           v_init: np.ndarray, \n",
      "           w_init: np.ndarray, \n",
      "           fk_taud: float, \n",
      "           t_eval: List[float]) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
      "    \"\"\"\n",
      "    Solves the 2D reaction-diffusion system for a batch of initial conditions\n",
      "    using the Forward Euler method on a GPU-accelerated backend.\n",
      "\n",
      "    Args:\n",
      "        u_init (np.ndarray): Initial conditions for u, shape [batch_size, N, N].\n",
      "        v_init (np.ndarray): Initial conditions for v, shape [batch_size, N, N].\n",
      "        w_init (np.ndarray): Initial conditions for w, shape [batch_size, N, N].\n",
      "        fk_taud (float): Model parameter tau_d.\n",
      "        t_eval (List[float]): A list of time points at which to evaluate and return the solution.\n",
      "\n",
      "    Returns:\n",
      "        Tuple[torch.Tensor, torch.Tensor, torch.Tensor]: A tuple containing the solutions\n",
      "        for u, v, and w at the specified time points (including t=0). Each tensor has a\n",
      "        shape of [batch_size, len(t_eval) + 1, N, N].\n",
      "    \"\"\"\n",
      "    # 1. Setup device and parameters\n",
      "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
      "    print(f\"Using device: {device}\")\n",
      "\n",
      "    params = {\n",
      "        'diffCoef': 0.001, 'C_m': 1.0, 'tau_pv': 7.99, 'tau_v1': 9.8,\n",
      "        'tau_v2': 312.5, 'tau_pw': 870.0, 'tau_mw': 41.0, 'tau_d': fk_taud,\n",
      "        'tau_0': 12.5, 'tau_r': 33.83, 'tau_si': 29.0, 'k': 10.0,\n",
      "        'V_csi': 0.861, 'V_c': 0.13, 'V_v': 0.04\n",
      "    }\n",
      "\n",
      "    # 2. Discretization setup\n",
      "    if u_init.shape[1] != u_init.shape[2]:\n",
      "        raise ValueError(\"Spatial domain must be square (N x N).\")\n",
      "    N = u_init.shape[1]\n",
      "    domain_size = 20.0  # Domain is [-10, 10], so total width/height is 20.0\n",
      "    dx = domain_size / (N - 1)\n",
      "\n",
      "    # Choose a small, fixed time step `dt` for the Forward Euler method.\n",
      "    # A conservative value is chosen to maintain stability, which is often\n",
      "    # dictated by the fastest reaction dynamics in such systems.\n",
      "    dt = 0.1\n",
      "    print(f\"Spatial step dx = {dx:.4f}, Time step dt = {dt:.4f}\")\n",
      "\n",
      "    # 3. Initialization\n",
      "    # Convert numpy inputs to torch tensors, set data type, and move to the selected device.\n",
      "    u = torch.from_numpy(u_init).float().to(device)\n",
      "    v = torch.from_numpy(v_init).float().to(device)\n",
      "    w = torch.from_numpy(w_init).float().to(device)\n",
      "\n",
      "    # Ensure t_eval is sorted to process time points chronologically.\n",
      "    t_eval_sorted = sorted(t_eval)\n",
      "    \n",
      "    # Store results in lists. Start with the initial state (t=0).\n",
      "    # We clone and move to CPU to prevent GPU memory accumulation and modification of stored states.\n",
      "    u_all = [u.cpu().clone()]\n",
      "    v_all = [v.cpu().clone()]\n",
      "    w_all = [w.cpu().clone()]\n",
      "\n",
      "    # 4. Main time-stepping loop\n",
      "    current_t = 0.0\n",
      "    \n",
      "    for i, target_t in enumerate(t_eval_sorted):\n",
      "        # Ensure we don't simulate backwards if target_t is less than current_t\n",
      "        if target_t > current_t:\n",
      "            # Calculate the number of steps required to reach the next evaluation time.\n",
      "            num_steps = math.ceil((target_t - current_t) / dt)\n",
      "            \n",
      "            for _ in range(num_steps):\n",
      "                # Calculate the diffusion term (Laplacian) for u.\n",
      "                lap_u = _compute_laplacian_2d(u, dx)\n",
      "                dudt_diffusion = params['diffCoef'] * lap_u\n",
      "                \n",
      "                # Calculate the reaction terms for all three variables.\n",
      "                dudt_reaction, dvdt, dwdt = _compute_reactions(u, v, w, params)\n",
      "                \n",
      "                # Perform the Forward Euler update step for each variable.\n",
      "                # Note the minus sign for dudt_reaction, as specified in the PDE.\n",
      "                u = u + dt * (dudt_diffusion - dudt_reaction)\n",
      "                v = v + dt * dvdt\n",
      "                w = w + dt * dwdt\n",
      "            \n",
      "            # Update the simulation time to reflect the steps taken.\n",
      "            current_t += num_steps * dt\n",
      "        \n",
      "        print(f\"Reached evaluation time point {target_t} at simulation time {current_t:.2f} (step {i+1}/{len(t_eval_sorted)})\")\n",
      "\n",
      "        # Store the computed state at the current time point.\n",
      "        u_all.append(u.cpu().clone())\n",
      "        v_all.append(v.cpu().clone())\n",
      "        w_all.append(w.cpu().clone())\n",
      "\n",
      "    # 5. Output formatting\n",
      "    # Stack the list of tensors along a new time dimension (dim=1).\n",
      "    # The output shape will be [batch_size, len(t_eval) + 1, N, N].\n",
      "    # Note: The requested output shape [..., N] in the prompt is assumed to be a typo\n",
      "    # for a 2D problem, so [..., N, N] is produced.\n",
      "    u_out = torch.stack(u_all, dim=1)\n",
      "    v_out = torch.stack(v_all, dim=1)\n",
      "    w_out = torch.stack(w_all, dim=1)\n",
      "    \n",
      "    print(\"Solver finished.\")\n",
      "\n",
      "    return u_out, v_out, w_out\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "client = genai.Client(api_key=api_key)\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-pro\", \n",
    "    config=GenerateContentConfig(\n",
    "            system_instruction=system_prompt\n",
    "        ),\n",
    "    contents=user_prompt    \n",
    "    )\n",
    "\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf67c7e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Open resp.md to view.\n"
     ]
    }
   ],
   "source": [
    "# Simple one-liner to save the response\n",
    "with open(\"resp.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(response.text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "codePDE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
